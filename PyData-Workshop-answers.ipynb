{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing medical image analysis tools in Python with Scikit-image Workshop\n",
    "### PyData Cambridge 14/11/2019\n",
    "#### Author: Frank Longford\n",
    "\n",
    "This notebook will guide users through a tutorial that will explore the scikit-image library to construct a pipeline for medical image analysis.\n",
    "\n",
    "Our aim is to derive a set of operations that will both automatically segment and analyse a microscope slide.\n",
    "\n",
    "First we import all necessary packages, including NumPy and Matplotlib, and a couple of useful plotting functions from our local `plotting` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plotting import plot_image, plot_image_and_hist, plot_tensor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing an Image\n",
    "\n",
    "If importing an image from file, use the `skimage.io.imread` function, which has pretty versitile file format handling (uses `pil` / `matplotlib` / `tiffile` loaders). If importing an image which is not in hexadecimal format (high colour resolution), then it is probably preferred to load it in as a NumPy array.\n",
    "\n",
    "Inside the repository you will find an file named `cell_example.tif`, complete the cell below to load in the image and view it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "# Import the cell_example.tif file usingskimage.io.imread function\n",
    "\n",
    "image = imread(\"cell_example.tif\")\n",
    "\n",
    "plot_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a grayscale image of a microscpe slide containing a number of cells. Before looking at this image we can already tell that it is in grayscale format due to the shape (512, 512).\n",
    "\n",
    "For the rest of this tutoral we shall use the `skimage.data.immunohistochemistry` example resource, which is supplied along with other demo images in the `skimage.data` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.data import immunohistochemistry\n",
    "# Import an example image using the skimage.data.immunohistochemistry function \n",
    "\n",
    "rgb_image = immunohistochemistry()\n",
    "\n",
    "plot_image(rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a colour image of a microscpe slide demonstrating immunohistochemical (IHC) stained cells. Before looking at this image we can already tell that it is in RGB format due to the shape (512, 512, 3). We are able to convert between RGB and grayscale formats using the `skimage.color.rgb2gray` conversion tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "# Convert the color image to grayscale using the skimage.color.rgb2gray function\n",
    "\n",
    "grayscale = rgb2gray(rgb_image)\n",
    "\n",
    "plot_image([rgb_image, grayscale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "We can apply some operations to both grayscale and RGB versions of our image. These typically include\n",
    "\n",
    "1) Filtering\n",
    "\n",
    "2) Equalization\n",
    "\n",
    "3) Restoration\n",
    "\n",
    "Throughout this section will shall refer to the greyscale image as $f(x, y)$.\n",
    "\n",
    "### Filtering\n",
    "\n",
    "Filtering is typically achived by performing a convolution of the entire image using another function $h(x, y)$.\n",
    "\n",
    "$g(x, y) = h(x, y) * f(x, y) = \\int\\limits_{s=-\\infty}^\\infty\\int\\limits_{t=-\\infty}^\\infty h(s, t) f(x + s, y + t) \\:ds\\:dt$\n",
    "\n",
    "One of the most common filters uses a Gaussian function to perform this convolution. In which case, we also need to provide a value for the standard deviation $\\sigma$ of the distribution.\n",
    "\n",
    "$h(x, y, \\sigma) = \\frac{1}{2\\pi\\sigma^2} \\exp\\left[-\\frac{x^2 + y^2}{2\\sigma^2}\\right]$\n",
    "\n",
    "Below we apply the `skimage.filters.gaussian` function to our RGB and grayscale images. The only extra information that we should supply to the function for an RGB image is to set the keyword argument `multichannel=True`, so that `gaussian` interprets the format of the NumPy array accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "# Smooth both RGB and grayscale images using the skimage.filters.gaussian filter\n",
    "\n",
    "smooth_rgb_image = gaussian(rgb_image, sigma=3, multichannel=True)\n",
    "smooth_grayscale = gaussian(grayscale, sigma=3)\n",
    "\n",
    "plot_image_and_hist([rgb_image, smooth_rgb_image, grayscale, smooth_grayscale],\n",
    "                    ['Original Colour', 'Gaussian smoothed',\n",
    "                     'Original Greyscale', 'Gaussian Smoothed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Filtering\n",
    "\n",
    "Kernel filtering, or smoothing can be performed by performing a convolution over a region around each pixel with an applied matrix (or kernel) $\\omega$ that defines the weight contributions of each pixel in the region.\n",
    "\n",
    "$g(x, y) = \\omega(x, y) * f(x, y) = \\sum\\limits_{s=-a}^a\\sum\\limits_{t=-b}^b \\omega(s, t) f(x - s, y - t)$\n",
    "\n",
    "For example, calculating the mean value for a 3 x 3 region around each pixel is the equivalent of applying a mean filter using the kernel matrix:\n",
    "\n",
    "$\\omega = \\frac{1}{9} \\left(\\begin{array}{lll} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{array}\\right)$\n",
    "\n",
    "For RGB images, the convolution is performed in each channel independently. \n",
    "\n",
    "In scikit-image, most kernel filters are located in the `skimage.filters.rank` module, whilst binary objects that define the shape of the kernels themselves (termed `selem`) are contained in the `skimage.morphology` module. In the example above, the selem would contain a 3 x 3 square matrix where each value is set to 1. The filter function (in this case, then mean) is then performed on top of this selem, which leads to the form of $\\omega$ provided. If we wanted to use a different mean kernel that only included pixels within a certain radian integer distance (shown below), we can use the `disk` selem instead, resulting in the following equivalent expression for $\\omega$:\n",
    "\n",
    "$\\omega = \\frac{1}{5} \\left(\\begin{array}{lll} 0 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 0 \\end{array}\\right)$ \n",
    "\n",
    "In reality, a selem is just a binary NumPy array - additional selems found in the `skimage.morphology` module include `rectangle` and `star`, but you can also contribute any NumPy Array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import square, disk, rectangle\n",
    "\n",
    "square_selem = square(3)\n",
    "disk_selem = disk(2)\n",
    "rectangle_selem = rectangle(4, 3)\n",
    "\n",
    "print(\"{} \\n {} {} \\n\".format(square_selem, type(square_selem), square_selem.dtype))\n",
    "print(\"{} \\n {} {} \\n\".format(disk_selem, type(disk_selem), disk_selem.dtype))\n",
    "print(\"{} \\n {} {} \\n\".format(rectangle_selem, type(rectangle_selem), rectangle_selem.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of how different filters can affect the pixel intensity distribution of our image is given below. Here we apply the `skimage.filters.rank.mean`, `skimage.filters.rank.median` and `skimage.filters.rank.mean.bilateral` filters, using the same selem `disk(5)`.\n",
    "\n",
    "The Bilateral Mean filter is particulary useful, as it is able to retain the contrast between different areas of detail whilst also reducing the overall noise. This is achieved by including the intensity as an extra component in $\\omega$ that takes into account the difference in pixel intensities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters.rank import mean, median, mean_bilateral\n",
    "# Use a selem of your choice to perform mean, median and bilateral kernel \n",
    "# filtering on our grayscale image\n",
    "\n",
    "selem = disk(8)\n",
    "\n",
    "mean_filter = mean(grayscale, selem)\n",
    "median_filter = median(grayscale, selem)\n",
    "bilateral_mean_filter = mean_bilateral(grayscale, selem)\n",
    "\n",
    "plot_image_and_hist([grayscale, mean_filter,\n",
    "                     median_filter, bilateral_mean_filter],\n",
    "                    ['Original Image', 'Mean Filter',\n",
    "                     'Median Filter', 'Bilateral Mean Filter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalisation\n",
    "\n",
    "Often an image may suffer from under or over exposure, leading to an imbalance in contrast. Shot-noise may also lead to certain pixels having an artifically high or low intensity, which will affect any derivative-derived properties. Equalization of an image's pixel distribution can provide a way to remove such artefacts.\n",
    "\n",
    "The next cell creates an artificially over-exposed image by applying a Gaussian function located on the centre pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "def normalise(array):\n",
    "    \"\"\"Normalises all values in an array to lie between 0-1\"\"\"\n",
    "    lower, upper = np.percentile(array, (0, 100))\n",
    "    \n",
    "    normalised = rescale_intensity(array, in_range=(lower, upper))\n",
    "    \n",
    "    return normalised\n",
    "\n",
    "def gaussian_kernel(kernlen=21, std=3):\n",
    "    \"\"\"Returns a 2D Gaussian kernel array.\"\"\"\n",
    "    \n",
    "    gkern1d = signal.gaussian(kernlen, std=std).reshape(kernlen, 1)\n",
    "    \n",
    "    gkern2d = np.outer(gkern1d, gkern1d)\n",
    "    \n",
    "    return gkern2d\n",
    "\n",
    "\n",
    "imbalanced = grayscale * (1 + 0.5 * gaussian_kernel(grayscale.shape[0], std=50))\n",
    "\n",
    "imbalanced = normalise(imbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to rescale the intensities with the `rescale_intensity` function to lie with the range of 2-98% of thier original values. This will remove the extrema values, resulting in a more even distribution at the loss of some local details.\n",
    "\n",
    "A slightly more intelligent equalisation method is to rescale the intensities until they yeild a linear culumative distribution function, which can be performed by calling `equalize_hist`. Again, this is performed on the entire image and so some local detail can be lost. Alternatively, the adaptive equalization routine `equalize_adapthist` performs the same procedure, yet over a specified local kernel (the shape of which can be set using the `kernel_size` keyword argument). Therefore the global intensity distribution will not be linear and some local features will be retained. This is particulary useful if we have an exposure imbalance in an image, leading to some areas being lighter than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist, equalize_hist\n",
    "# Complete the cell by using the rescale_intensity, equalize_adapthist and equalize_hist\n",
    "# functions. In order to get the pixel values that represent 2% and 98% of the overall\n",
    "# distribution, we typically use the np.percentile function (see cell above)\n",
    "\n",
    "# Contrast stretching\n",
    "p2, p98 = np.percentile(imbalanced, (2, 98))\n",
    "img_rescale = rescale_intensity(imbalanced, in_range=(p2, p98))\n",
    "\n",
    "# Equalization\n",
    "img_eq = equalize_hist(imbalanced)\n",
    "\n",
    "# Adaptive Equalization\n",
    "img_adapteq = equalize_adapthist(imbalanced, kernel_size=(16, 16))\n",
    "\n",
    "plot_image_and_hist([imbalanced, img_rescale, img_eq, img_adapteq],\n",
    "                    ['Low contrast image', 'Contrast stretching',\n",
    "                     'Histogram equalization', 'Adaptive equalization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoration\n",
    "\n",
    "One extra state-of-the-art filtering method in scikit-image is the non-local means algorithm, which attempts to restore features of an image that may have been lost due to noise.\n",
    "\n",
    "The next cell creates an artificially noisy image by applying a Gaussian distribution of random values using a standard deviation of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "\n",
    "sigma = 0.1\n",
    "\n",
    "noisy_image = random_noise(rgb_image, var=sigma**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-local means algorithm works in a similar way to the bilateral mean, whereby the local mean of each pixel is first calculated for a given kernel $\\omega(x, y)$ as $\\mathbf{B}(x, y)$. \n",
    "\n",
    "$\\mathbf{B}(x, y) = \\sum\\limits_{s=-a}^a\\sum\\limits_{t=-b}^b \\omega(s, t) f(x - s, y - t)$\n",
    "\n",
    "A Gaussian convolution is then performed using the difference in pixel intensities of $\\mathbf{B}(x, y)$ to calculate the weights,\n",
    "\n",
    "$h(x, y, s, t) = \\exp\\left[-\\frac{|\\mathbf{B}(x - s, y - t)- \\mathbf{B}(x, y)|^2}{\\sigma^2}\\right]$\n",
    "\n",
    "so that the full convolution is given by,\n",
    "\n",
    "$g(x, y) = \\frac{1}{C(x, y)}\\int\\limits_{s=-\\infty}^\\infty\\int\\limits_{t=-\\infty}^\\infty h(x, y, s, t) f(x - s, y - t) \\:ds\\:dt$\n",
    "\n",
    "with a normalisaing factor\n",
    "\n",
    "$C(x, y) = \\int\\limits_{s=-\\infty}^\\infty\\int\\limits_{t=-\\infty}^\\infty h(x, y, s, t) \\:ds\\:dt$\n",
    "\n",
    "In reality, the integrals shown above are performed as partial integrals over local region around each pixel. As a rule of thumb, the size of these integrals can be estimated from the amount of noise in the image. The `skimage.restoration.estimate_sigma` function can provide an estimation of the standard deviation of noise, assuming a normal distribution (white noise).\n",
    "\n",
    "The code below performs the non-local means algorithm using a square kernel of size `patch_size` for calculating $\\mathbf{B}(x, y)$, a partial integral cutoff of length `h`, and a Gaussian standard deviation $\\sigma$ of `sigma`. An appropriate value for the cutoff length can normally be estimated as between 0.5-1.0 $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import estimate_sigma, denoise_nl_means\n",
    "# Complete the cell to apply the skimage.restoration.denoise_nl_means algorithm to our\n",
    "# noisy_image. Try to estimate the appropriate value of sigma to use from the\n",
    "# estimate_sigma function\n",
    "\n",
    "sigma_est = estimate_sigma(noisy_image, multichannel=True)\n",
    "\n",
    "sigma_est = np.mean(sigma_est)\n",
    "\n",
    "print('Actual noise std: {}  Estimated noise std = {}'.format(sigma, sigma_est))\n",
    "\n",
    "restored_image = denoise_nl_means(\n",
    "    noisy_image, patch_size=5, h=0.6 * sigma_est, \n",
    "    sigma=sigma_est, fast_mode=True, multichannel=True)\n",
    "\n",
    "plot_image_and_hist([rgb_image, noisy_image,\n",
    "                     restored_image],\n",
    "                    ['Original Image', 'Noisy Image',\n",
    "                     'Non-local Means'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, pre-processing can be very useful and there are plenty of options readily available in scikit-image. We shall also see how these pre-processing operations can affect the performance of other algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Analysis\n",
    "\n",
    "Let's now explore some of the structural details of this greyscale image using the `skimage.feature.structure_tensor` and `skimage.feature.hessian_matrix` routines. Both use numerical estimates of the derivates of $f(x, y)$ to extract properties of the image, in the same way we might investigate propertes of a surface.\n",
    "\n",
    "### Structure Tensor\n",
    "\n",
    "Using our greyscale, single channel image, $f(x, y)$, we can examine the structure tensor to obtain information on the primary derivatives (the Jacobian $\\mathbf{J}(x, y)$).\n",
    "\n",
    "$\\mathbf{J}(x, y) = \\left[\\frac{\\partial f(x, y)}{\\partial x}, \\frac{\\partial f(x, y)}{\\partial y}\\right]$\n",
    "\n",
    "Generally the estimation of each derivative is computed by the Sobel transform\n",
    "\n",
    "$\\mathbf{J}(x, y) \\approx \\left[\\omega(x, y) * f(x, y),\\; \\omega^{\\mathbf{T}}(x, y) * f(x, y)\\right]$\n",
    "\n",
    "where\n",
    "\n",
    "$\\omega = \\begin{bmatrix} \n",
    " -1 & 0 & +1  \\\\\n",
    "-2 & 0 & +2 \\\\\n",
    "-1 & 0 & +1 \n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sobel_h, sobel_v\n",
    "\n",
    "jacobian = [sobel_h(grayscale), sobel_v(grayscale)]\n",
    "\n",
    "plot_image(jacobian, titles=[r'$\\mathbf{J}_{x}(x, y)$', r'$\\mathbf{J}_{y}(x, y)$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure tensor $\\mathbf{A}(x, y)$ is defined as\n",
    "\n",
    "$\\begin{align} \n",
    "    \\mathbf{A}(x, y) &= \\mathbf{J}(x, y) \\cdot \\mathbf{J}^{\\mathbf{T}}(x, y) \\\\\n",
    "    &= \\left[\\begin{array}{cc} \n",
    "        \\mathbf{J}_{x}(x, y)^2 & \\mathbf{J}_{x}(x, y)\\mathbf{J}_{y}(x, y) \\\\\n",
    "        \\mathbf{J}_{x}(x, y)\\mathbf{J}_{y}(x, y) & \\mathbf{J}_{y}(x, y)^2\n",
    "    \\end{array}\\right]\n",
    "\\end{align}$\n",
    "\n",
    "Therefore we can see that there are only 3 unique elements in this 2 x 2 tensor, $\\mathbf{A}_{xx}(x, y)$, $\\mathbf{A}_{xy}(x, y)$ and $\\mathbf{A}_{yy}(x, y)$\n",
    "\n",
    "The function `skimage.feature.structure_tensor` calculates the unique elements of $\\mathbf{A}(x, y)$ using the Sobel transform, wilst also applying a Gaussian filter to each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import structure_tensor\n",
    "\n",
    "structure = structure_tensor(grayscale, sigma=0.1, mode='reflect')\n",
    "\n",
    "plot_image(structure,\n",
    "           titles = [r'$\\mathbf{A}_{xx}(x, y)$',\n",
    "                     r'$\\mathbf{A}_{xy}(x, y)$',\n",
    "                     r'$\\mathbf{A}_{yy}(x, y)$'],\n",
    "           cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalues $\\lambda_{max}$, $\\lambda_{min}$ and eigenvectors $e_{max}$, $e_{min}$ of the structure tensor can be interpreted as summaraising the distribution of gradients centered on pixel $x, y$. \n",
    "\n",
    "The anisotropy (or coherence) in gradient directions can be interpreted from the difference in eigenvalues,\n",
    "\n",
    "$n(x, y) = \\left(\\frac{\\lambda_{max} - \\lambda_{min}}{\\lambda_{max} + \\lambda_{min}}\\right)^2$\n",
    "\n",
    "with the overall direction is defined in terms of the Jacobian, \n",
    "\n",
    "$\\theta(x, y) = \\arctan\\left(\\frac{\\mathbf{J}_{y}(x, y)}{\\mathbf{J}_{x}(x, y)}\\right)$\n",
    "\n",
    "and the energy is defined in terms of the trace of the structure tensor\n",
    "\n",
    "$\\psi(x, y) = \\sqrt{{A}_{xx}(x, y) + {A}_{yy}(x, y)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import structure_tensor_eigvals\n",
    "\n",
    "def structure_properties(image):\n",
    "    # Complete the function to return the anisotropy, angle, energy\n",
    "    # values for each pixel in our image argument using the definitions\n",
    "    # above\n",
    "\n",
    "    image = normalise(image)\n",
    "    \n",
    "    jacobian = [sobel_h(image), sobel_v(image)]\n",
    "    structure = structure_tensor(image, sigma=0.5, mode='reflect')\n",
    "    \n",
    "    eig_val = structure_tensor_eigvals(*structure)\n",
    "    eig_diff = (eig_val[0] - eig_val[1])\n",
    "    eig_sum = eig_val[0] + eig_val[1]\n",
    "\n",
    "    anisotropy = np.divide(eig_diff, eig_sum)**2\n",
    "    angle = np.arctan(*jacobian)\n",
    "    energy = np.hypot(*jacobian)\n",
    "\n",
    "    return anisotropy, angle, energy\n",
    "\n",
    "\n",
    "anisotropy, angle, energy = structure_properties(grayscale)\n",
    "\n",
    "plot_image([anisotropy, angle, energy], titles=['Anisotropy', 'Angle', 'Energy'], cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that using the first derivatives can provide information on 'edge' like regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian Tensor\n",
    "\n",
    "Using our greyscale, single channel image, $f(x, y)$, we can examine the hessian tensor to obtain information on the secondary derivatives (the Hessian $\\mathbf{H}(x, y)$).\n",
    "\n",
    "$\\mathbf{H}(x, y) = \\left[\\begin{array}{cc} \n",
    "    \\frac{\\partial^2 f(x, y)}{\\partial x^2} & \\frac{\\partial^2 f(x, y)}{\\partial y\\partial x} \\\\\n",
    "    \\frac{\\partial^2 f(x, y)}{\\partial x\\partial y} & \\frac{\\partial^2 f(x, y)}{\\partial y^2}\n",
    "\\end{array}\\right]$\n",
    "\n",
    "In scikit-image, the secondard derivatives are estimated using a forward / backward approximataion (from `numpy.gradient`). Since the x and y components are treated as independent, again we can see that there are only 3 unique elements to this 2 x 2 tensor, $\\mathbf{H}_{xx}(x, y)$, $\\mathbf{H}_{xy}(x, y)$ and $\\mathbf{H}_{yy}(x, y)$. These are computed using the `skimage.feature.hessian_metrix` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hessian_matrix\n",
    "\n",
    "hessian = hessian_matrix(grayscale, sigma=0.5)\n",
    "\n",
    "plot_image(hessian, \n",
    "           titles = [r'$\\mathbf{H}_{xx}(x, y)$',\n",
    "                     r'$\\mathbf{H}_{xy}(x, y)$',\n",
    "                     r'$\\mathbf{H}_{yy}(x, y)$']\n",
    "           cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the second derivates can be interpreted as providing information on the curvature of the image. Therefore, they can be very useful to identify and enhance 'ridge' like regions, such as vessels, wrinkles or tubes.\n",
    "\n",
    "The Sato (or \"tubeness\") filter calculates the eigenvalues of the Hessian tensor for each pixel and applies a threshold method (in 2D)\n",
    "\n",
    "$T(x, y) = \\left\\{\\begin{array}{lll} |\\lambda_{min}| & \\text{if} & \\lambda_{min} < 0 \\\\ 0 & \\text{else} & \\end{array} \\right.$\n",
    "\n",
    "In scikit-image, the `skimage.filters.sato` function includes the option to calculate $T(x,y)$ for a range of Gaussian filters with varying $\\sigma$. The final outcome for each pixel is then provided by the maximum value of $T(x, y)$ calculated across all filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sato\n",
    "# Appliy the skimage.filters.sato function to our grayscale image, whilst\n",
    "# varying the sigmas keyword argument (list of floats)\n",
    "\n",
    "tubeness = sato(grayscale, black_ridges=False)\n",
    "\n",
    "plot_image([grayscale, tubeness], ['Original Image', 'Sato Filter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "Robust automatic segmentation of images is a highly desired outcome of any analysis pipeline. \n",
    "\n",
    "Filters are generally one of the first operations performed on an image to prepare it for segmentation. In the simplest of cases, identifying the edges of the image can provide enough information to form the boundary of each segment.\n",
    "\n",
    "The Canny filter uses both the angle and energy of each pixel to perform an edge finding algorithm and involves a Gaussian filter to 'wash out'  minor gradients, allowing only the larger features to be extracted. It is generally a good first choice when exploring different boundary finding filters. In sckit-image, it can be found in the `skimage.feature.canny` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import canny\n",
    "# Use the skimage.feature.canny fucntion to identify edges in our grayscale\n",
    "# image - play about with the value of Gaussian sigma to see how this affects the outcome\n",
    "canny_edges = canny(grayscale, sigma=1.5)\n",
    "\n",
    "plot_image([grayscale, canny_edges])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identifying edges, we can fill in the areas between them to create binary regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.morphology import binary_closing\n",
    "\n",
    "closed = binary_closing(canny_edges, selem=disk(2))\n",
    "\n",
    "binary_mask = binary_fill_holes(closed)\n",
    "\n",
    "plot_image([grayscale, canny_edges, binary_mask],\n",
    "          ['Original Image', 'Canny Filter', 'Binary Mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `skimage.measure.label` algorithm can then be used to label each connected region in a binary image. It returns a new array with an integer label for each pixel in the image representing the segement that it belongs to. Each segment is made up from pixels containing a binary value of 1 that are connected together spatially. The distance with which pixels are connected and therefore considered 'neighbours' can be altered using the `connectivity` kewyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb\n",
    "# Apply the skimage.measure.label algorithm to oour binary_mask. Experiement\n",
    "# with varying the value of the connectivity keyword argument to form labelled segments\n",
    "\n",
    "label_image = label(binary_mask)\n",
    "\n",
    "image_label_overlay = label2rgb(label_image, image=grayscale, bg_label=0)\n",
    "\n",
    "plot_image(image_label_overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the typical method to segment regions in images. Once a label image has been created, the `skimage.measure.regionprops` algorithm can be used to create a list of `RegionProperties` objects representing each segment. These objects have attributes providing metrics to describe the segment's content, size and shape. The keyword argument `intensity_image` can also be used to provide the original image as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "# Apply the skimage.measure.regionprops algorithm to the label_image array\n",
    "# in order to extract a list of RegionProperties object describing each segment.\n",
    "\n",
    "regions = regionprops(label_image, intensity_image=grayscale)\n",
    "\n",
    "regions = [region for region in regions if region.area > 200]\n",
    "\n",
    "plot_image([region.intensity_image for region in regions],\n",
    "           [f'Region #{region.label}' for region in regions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use gray-level co-occurrence matrices (GLCM) to calculate properties that correspond to texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "# compute some GLCM properties each region\n",
    "xs = []\n",
    "ys = []\n",
    "for region in regions:\n",
    "    #xs.append(region.eccentricity)\n",
    "    \n",
    "    int_image = (region.intensity_image * 255).astype(int)\n",
    "    glcm = greycomatrix(int_image, [1, 2], [0, np.pi/4, np.pi/2, np.pi*3/4], 256,\n",
    "                        symmetric=True, normed=True)\n",
    "    glcm[0, :, :, :] = 0\n",
    "    glcm[:, 0, :, :] = 0\n",
    "    \n",
    "    xs.append(greycoprops(glcm, 'dissimilarity').mean())\n",
    "    ys.append(greycoprops(glcm, 'correlation').mean())\n",
    "    \n",
    "plt.scatter(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Based Segmentation\n",
    "\n",
    "Assuming that the color in stained microscope slides is relatively consistent, we can also attempt to cluster each pixel in an RGB image by its hue (unit RGB vector).\n",
    "\n",
    "This can be performed by using machine learning clustering algorithims supplied in the scikit-images library. Alternatively, scikit-image has some inbuilt tools to provide assistance for certain microscope stain patterns. The `skimage.color.seperate_strains` function contains many different conversion options to transform each channel into weightings representing the contribution of each color stain.\n",
    "\n",
    "Conversions for microscope stains currently included in scikit-image include:\n",
    "\n",
    "1. Hematoxylin + Eosin + DAB\n",
    "2. Hematoxylin + DAB\n",
    "3. Feulgen + Light Green\n",
    "4. Giemsa stain : Methyl Blue + Eosin\n",
    "5. FastRed + FastBlue +  DAB\n",
    "6. Methyl Green + DAB\n",
    "7. Hematoxylin + AEC\n",
    "8. Blue matrix Anilline Blue + Red matrix Azocarmine + Orange matrix Orange-G\n",
    "9. Methyl Blue + Ponceau Fuchsin\n",
    "10. Alcian Blue + Hematoxylin\n",
    "11. Hematoxylin + PAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import separate_stains, hed_from_rgb\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Create an artificial color close to the original one\n",
    "cmap_hema = LinearSegmentedColormap.from_list('mycmap', ['white', 'navy'])\n",
    "cmap_dab = LinearSegmentedColormap.from_list('mycmap', ['white',\n",
    "                                             'saddlebrown'])\n",
    "cmap_eosin = LinearSegmentedColormap.from_list('mycmap', ['darkviolet',\n",
    "                                               'white'])\n",
    "\n",
    "smoothed = gaussian(rgb_image)\n",
    "\n",
    "hed_image = separate_stains(smoothed, hed_from_rgb)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 6), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(rgb_image)\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(hed_image[:, :, 0], cmap=cmap_hema)\n",
    "ax[1].set_title(\"Hematoxylin\")\n",
    "\n",
    "ax[2].imshow(hed_image[:, :, 1], cmap=cmap_eosin)\n",
    "ax[2].set_title(\"Eosin\")\n",
    "\n",
    "ax[3].imshow(hed_image[:, :, 2], cmap=cmap_dab)\n",
    "ax[3].set_title(\"DAB\")\n",
    "\n",
    "for a in ax.ravel():\n",
    "    a.axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can clearly see that we can use the DAB stain to segment the cellualr regions from this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "def get_labels(mask):\n",
    "    \n",
    "    # Again, we fill in any holes for each region we shall segment\n",
    "    closed = binary_closing(thresholded, disk(3))\n",
    "\n",
    "    filled = binary_fill_holes(closed)\n",
    "\n",
    "    # label image regions\n",
    "    label_image = label(filled)\n",
    "    \n",
    "    return label_image\n",
    "\n",
    "\n",
    "# We use the channel that corresponds to the DAB color in our IHC stained image\n",
    "dab_image = hed_image[:, :, 2]\n",
    "\n",
    "# Here we threshold the image to remove the background\n",
    "thresholded = dab_image > threshold_isodata(dab_image)\n",
    "\n",
    "# label image regions\n",
    "dab_label_image = get_labels(thresholded)\n",
    "\n",
    "image_label_overlay = label2rgb(dab_label_image, image=grayscale, bg_label=0)\n",
    "\n",
    "plot_image([rgb_image, image_label_overlay])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension\n",
    "\n",
    "More information about textures can be obtained using grey level correlation matricies (GLCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the channel that corresponds to the Hema color in our IHC stained image\n",
    "hema_image = hed_image[:, :, 0]\n",
    "\n",
    "# Here we threshold the image to remove the background\n",
    "thresholded = (hema_image > threshold_isodata(hema_image)) * (dab_image < threshold_isodata(dab_image))\n",
    "\n",
    "# label image regions\n",
    "hema_label_image = get_labels(threshold)\n",
    "\n",
    "image_label_overlay = label2rgb(hema_label_image, image=grayscale, bg_label=0)\n",
    "\n",
    "plot_image([rgb_image, image_label_overlay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regionprops(hema_label_image, intensity_image=grayscale)\n",
    "\n",
    "# compute some GLCM properties each patch\n",
    "xs = []\n",
    "ys = []\n",
    "for region in regions:\n",
    "    #xs.append(region.eccentricity)\n",
    "    \n",
    "    int_image = (region.intensity_image * 255).astype(int)\n",
    "    glcm = greycomatrix(int_image, [1, 2], [0, np.pi/4, np.pi/2, np.pi*3/4], 256,\n",
    "                        symmetric=True, normed=True)\n",
    "    glcm[0, :, :, :] = 0\n",
    "    glcm[:, 0, :, :] = 0\n",
    "    \n",
    "    xs.append(greycoprops(glcm, 'dissimilarity').mean())\n",
    "    ys.append(greycoprops(glcm, 'correlation').mean())\n",
    "    \n",
    "plt.scatter(xs, ys)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
